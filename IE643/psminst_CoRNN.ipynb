{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.10.12","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"gpu","dataSources":[],"dockerImageVersionId":30588,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":true},"colab":{"provenance":[]}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n\n# Input data files are available in the read-only \"../input/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('/kaggle/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 20GB to the current directory (/kaggle/working/) that gets preserved as output when you create a version using \"Save & Run All\"\n# You can also write temporary files to /kaggle/temp/, but they won't be saved outside of the current session","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","id":"w831ki6K4SbR","execution":{"iopub.status.busy":"2023-11-27T16:16:12.954040Z","iopub.execute_input":"2023-11-27T16:16:12.954750Z","iopub.status.idle":"2023-11-27T16:16:13.296056Z","shell.execute_reply.started":"2023-11-27T16:16:12.954718Z","shell.execute_reply":"2023-11-27T16:16:13.295052Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"from torch import nn\nimport torch\nfrom torch.autograd import Variable\nimport math\n\nclass coRNNCell(nn.Module):\n    def __init__(self, n_inp, n_hid, dt, gamma, epsilon):\n        super(coRNNCell, self).__init__()\n        self.dt = dt\n        self.gamma = gamma\n        self.epsilon = epsilon\n        self.i2h = nn.Linear(n_inp + n_hid + n_hid, n_hid)\n#         self.bn = nn.BatchNorm1d(n_hid)\n#         self.dropout = nn.Dropout(0.5)\n\n    def forward(self,x,hy,hz):\n        hz = hz + self.dt * (torch.tanh(self.i2h(torch.cat((x, hz, hy),1)))\n                                   - self.gamma * hy - self.epsilon * hz)\n        hy = hy + self.dt * hz\n\n        return hy, hz\n\nclass coRNN(nn.Module):\n    def __init__(self, n_inp, n_hid, n_out, dt, gamma, epsilon):\n        super(coRNN, self).__init__()\n        self.n_hid = n_hid\n        self.cell = coRNNCell(n_inp,n_hid,dt,gamma,epsilon)\n        self.readout = nn.Linear(n_hid, n_out)\n#         self.bn = nn.BatchNorm1d(n_hid)\n#         self.dropout = nn.Dropout(0.3)\n\n    def forward(self, x):\n        ## initialize hidden states\n        hy = Variable(torch.zeros(x.size(1),self.n_hid))\n        hz = Variable(torch.zeros(x.size(1),self.n_hid))\n\n        for t in range(x.size(0)):\n            hy, hz = self.cell(x[t],hy,hz)\n        output = self.readout(hy)\n\n        return output\n","metadata":{"id":"ve1EQpqy4SbR","execution":{"iopub.status.busy":"2023-11-27T16:16:13.297597Z","iopub.execute_input":"2023-11-27T16:16:13.297992Z","iopub.status.idle":"2023-11-27T16:16:16.738067Z","shell.execute_reply.started":"2023-11-27T16:16:13.297965Z","shell.execute_reply":"2023-11-27T16:16:16.737086Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"class Myclass:\n    def __init__(self):\n      self.n_hid = 256\n      self.T = 100\n      self.max_steps = 60000\n      self.log_interval = 100\n      self.batch = 120\n      self.batch_test = 1000\n      self.lr = 0.0021\n      self.dt = 0.042\n      self.gamma = 2.7\n      self.epsilon = 4.7\n      self.epochs = 120\n\nargs = Myclass()","metadata":{"id":"d8N05QKU4SbS","execution":{"iopub.status.busy":"2023-11-27T16:16:17.919641Z","iopub.execute_input":"2023-11-27T16:16:17.920108Z","iopub.status.idle":"2023-11-27T16:16:17.926036Z","shell.execute_reply.started":"2023-11-27T16:16:17.920079Z","shell.execute_reply":"2023-11-27T16:16:17.925086Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"import torch\nimport torchvision\nimport torchvision.transforms as transforms\n\ndef get_data(bs_train,bs_test):\n    train_dataset = torchvision.datasets.MNIST(root='data/',\n                                               train=True,\n                                               transform=transforms.ToTensor(),\n                                               download=True)\n\n    test_dataset = torchvision.datasets.MNIST(root='data/',\n                                              train=False,\n                                              transform=transforms.ToTensor())\n\n    train_dataset, valid_dataset = torch.utils.data.random_split(train_dataset, [57000,3000])\n\n    # Data loader\n    train_loader = torch.utils.data.DataLoader(dataset=train_dataset,\n                                               batch_size=bs_train,\n                                               shuffle=True)\n\n    valid_loader = torch.utils.data.DataLoader(dataset=valid_dataset,\n                                              batch_size=bs_test,\n                                              shuffle=False)\n\n    test_loader = torch.utils.data.DataLoader(dataset=test_dataset,\n                                              batch_size=bs_test,\n                                              shuffle=False)\n\n    return train_loader, valid_loader, test_loader","metadata":{"id":"r1KqZTel4SbS","execution":{"iopub.status.busy":"2023-11-27T16:17:19.441208Z","iopub.execute_input":"2023-11-27T16:17:19.441564Z","iopub.status.idle":"2023-11-27T16:17:19.449477Z","shell.execute_reply.started":"2023-11-27T16:17:19.441535Z","shell.execute_reply":"2023-11-27T16:17:19.448378Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"from torch import nn, optim\nimport torch\n# import network\nimport torch.nn.utils\n# import utils\nfrom pathlib import Path\nimport argparse\n\ntorch.manual_seed(46159)\n\nn_inp = 1\nn_out = 10\nbs_test = 1000\n\nmodel = coRNN(n_inp, args.n_hid, n_out,args.dt,args.gamma,args.epsilon)\n\nobjective = nn.CrossEntropyLoss()\noptimizer = optim.Adam(model.parameters(), lr=args.lr)","metadata":{"id":"MG7oFyF04SbU","execution":{"iopub.status.busy":"2023-11-27T16:17:21.512343Z","iopub.execute_input":"2023-11-27T16:17:21.512730Z","iopub.status.idle":"2023-11-27T16:17:21.543707Z","shell.execute_reply.started":"2023-11-27T16:17:21.512693Z","shell.execute_reply":"2023-11-27T16:17:21.542910Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"model","metadata":{"id":"dhDA7yHP4SbU","outputId":"dad17a76-9376-46d4-b0f8-25bd3a91f49f","execution":{"iopub.status.busy":"2023-11-27T16:17:24.168299Z","iopub.execute_input":"2023-11-27T16:17:24.168949Z","iopub.status.idle":"2023-11-27T16:17:24.175602Z","shell.execute_reply.started":"2023-11-27T16:17:24.168915Z","shell.execute_reply":"2023-11-27T16:17:24.174729Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"train_loader, valid_loader, test_loader = get_data(args.batch,bs_test)\n# print(train_loader.shape)","metadata":{"id":"SQjw_oP94SbU","execution":{"iopub.status.busy":"2023-11-27T16:17:26.864704Z","iopub.execute_input":"2023-11-27T16:17:26.865072Z","iopub.status.idle":"2023-11-27T16:17:27.926145Z","shell.execute_reply.started":"2023-11-27T16:17:26.865041Z","shell.execute_reply":"2023-11-27T16:17:27.925095Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"from PIL import Image\ndownloaded_images_count = 0\nnum_images_to_download = 20\noutput_directory = 'downloaded_images/'\nos.makedirs(output_directory, exist_ok=True)\n# Iterate over the test_loader\nfor batch_idx, (images, labels) in enumerate(test_loader):\n    # Iterate over images in the batch\n    for image_idx in range(images.size(0)):\n        # Check if the desired number of images has been downloaded\n        if downloaded_images_count >= num_images_to_download:\n            break\n\n        # Extract the image and label\n        image = images[image_idx].squeeze().numpy()\n        label = labels[image_idx].item()\n\n        # Convert the NumPy array to a PIL Image\n        pil_image = Image.fromarray((image * 255).astype('uint8'), mode='L')\n\n        # Save the image with its label as the filename\n        filename = f\"{label}_{downloaded_images_count}.png\"\n        pil_image.save(os.path.join(output_directory, filename))\n\n        # Increment the downloaded images count\n        downloaded_images_count += 1\n\n    # Check if the desired number of images has been downloaded\n    if downloaded_images_count >= num_images_to_download:\n        break\n\nprint(f\"{downloaded_images_count} images downloaded to {output_directory}\")\n","metadata":{"execution":{"iopub.status.busy":"2023-11-27T16:17:31.025711Z","iopub.execute_input":"2023-11-27T16:17:31.026461Z","iopub.status.idle":"2023-11-27T16:17:31.197612Z","shell.execute_reply.started":"2023-11-27T16:17:31.026425Z","shell.execute_reply":"2023-11-27T16:17:31.196461Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"for i, (images, labels) in enumerate(train_loader):\n    print(images.shape)\n    break","metadata":{"id":"vCXS98Cj4SbU","outputId":"a7865d8b-cdc0-4633-f125-e1c26d9a7fff","execution":{"iopub.status.busy":"2023-11-26T23:41:43.543349Z","iopub.execute_input":"2023-11-26T23:41:43.543709Z","iopub.status.idle":"2023-11-26T23:41:43.588682Z","shell.execute_reply.started":"2023-11-26T23:41:43.543676Z","shell.execute_reply":"2023-11-26T23:41:43.587862Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def test(data_loader):\n    model.eval()\n    correct = 0\n    test_loss = 0\n    with torch.no_grad():\n        for i, (images, labels) in enumerate(data_loader):\n            images = images.reshape(bs_test, 1, 784)\n            images = images.permute(2, 0, 1)\n\n            output = model(images)\n            test_loss += objective(output, labels).item()\n            pred = output.data.max(1, keepdim=True)[1]\n            correct += pred.eq(labels.data.view_as(pred)).sum()\n    test_loss /= i+1\n    accuracy = 100. * correct / len(data_loader.dataset)\n\n    return accuracy.item()\n\n\n","metadata":{"id":"fwuVo8tW4SbV","execution":{"iopub.status.busy":"2023-11-26T23:41:43.589795Z","iopub.execute_input":"2023-11-26T23:41:43.590075Z","iopub.status.idle":"2023-11-26T23:41:43.596658Z","shell.execute_reply.started":"2023-11-26T23:41:43.590051Z","shell.execute_reply":"2023-11-26T23:41:43.595675Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"clip_value = 0.5\nt=0\nj=0\nbest_valid_accuracy = 0.0\nbest_model_state_dict = None\nfor epoch in range(args.epochs):\n    t=0\n    j=j+1\n    print(\"big loop %d\",j)\n    model.train()\n    for i, (images, labels) in enumerate(train_loader):\n        images = images.reshape(args.batch, 1, 784)\n        images = images.permute(2, 0, 1)\n\n        optimizer.zero_grad()\n        output = model(images)\n#         print(output.shape)\n        t=t+1\n        print(t)\n        loss = objective(output, labels)\n        loss.backward()\n#         torch.nn.utils.clip_grad_norm_(model.parameters(), clip_value)\n        optimizer.step()\n    valid_acc = test(valid_loader)\n    test_acc = test(test_loader)\n    if valid_acc > best_valid_accuracy:\n        best_valid_accuracy = valid_acc\n        best_model_state_dict = model.state_dict()\n        torch.save(model.state_dict(), 'pminst_model_checkpoint.pth')\n        print(best_valid_accuracy)\n    Path('result').mkdir(parents=True, exist_ok=True)\n    f = open('result/sMNIST_log.txt', 'a')\n    if (epoch == 0):\n        f.write('## learning rate = ' + str(args.lr) + ', dt = ' + str(args.dt) + ', gamma = ' + str(args.gamma) + ', epsilon = ' + str(args.epsilon) + '\\n')\n    f.write('eval accuracy: ' + str(round(valid_acc, 2)) + '\\n')\n    f.close()\n\n    if (epoch+1) % 100 == 0:\n        args.lr /= 10.\n        for param_group in optimizer.param_groups:\n            param_group['lr'] = args.lr\n\nif best_model_state_dict is not None:\n    model.load_state_dict(best_model_state_dict)\n\n# Test the model\ntest_acc = test(test_loader)\n\nprint('Test set:  Accuracy: {:.2f}%\\n'.format(test_acc))\nf = open('result/sMNIST_log.txt', 'a')\nf.write('final test accuracy: ' + str(round(test_acc, 2)) + '\\n')\nf.close()","metadata":{"id":"UWlYUfDG4SbV","outputId":"7e9d0d58-d35e-4dfd-c2f3-7df68a51e52d","execution":{"iopub.status.busy":"2023-11-26T23:41:43.597875Z","iopub.execute_input":"2023-11-26T23:41:43.598152Z","iopub.status.idle":"2023-11-27T00:25:46.842780Z","shell.execute_reply.started":"2023-11-26T23:41:43.598118Z","shell.execute_reply":"2023-11-27T00:25:46.841581Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"test_acc = test(test_loader)\n\nprint('Test set:  Accuracy: {:.2f}%\\n'.format(test_acc))\nf = open('result/sMNIST_log.txt', 'a')\nf.write('final test accuracy: ' + str(round(test_acc, 2)) + '\\n')\nf.close()","metadata":{"execution":{"iopub.status.busy":"2023-11-27T00:27:04.643931Z","iopub.execute_input":"2023-11-27T00:27:04.644808Z","iopub.status.idle":"2023-11-27T00:27:22.928328Z","shell.execute_reply.started":"2023-11-27T00:27:04.644772Z","shell.execute_reply":"2023-11-27T00:27:22.927368Z"},"trusted":true},"execution_count":null,"outputs":[]}]}